{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Cultura e Pr√°ticas em DataOps e MLOps**\n",
    "\n",
    "\n",
    "- Por Daniel: realizando teste rodando este c√≥digo a partir de um ambiente Conda personalizado fornecido pelo professor da cadeira. Hoje √© segunda-feira 2025-11-17. Est√° instalado no meu Notebook Dell Alienware, de nome Antyliah, um banco de dados SQLite para dar suporte √† biblioteca MLflow.\n",
    "\n",
    "**Autor Professor**: Renan Santos Mendes\n",
    "**Email do PROFESSOR**: renansantosmendes@gmail.com\n",
    "\n",
    "**Descri√ß√£o**: Este notebook apresenta um exemplo de uma rede neural profunda com mais de uma camada para um problema de classifica√ß√£o.\n",
    "\n",
    "\n",
    "# **Sa√∫de Fetal**\n",
    "\n",
    "As Cardiotocografias (CTGs) s√£o op√ß√µes simples e de baixo custo para avaliar a sa√∫de fetal, permitindo que os profissionais de sa√∫de atuem na preven√ß√£o da mortalidade infantil e materna. O pr√≥prio equipamento funciona enviando pulsos de ultrassom e lendo sua resposta, lan√ßando luz sobre a frequ√™ncia card√≠aca fetal (FCF), movimentos fetais, contra√ß√µes uterinas e muito mais.\n",
    "\n",
    "Este conjunto de dados cont√©m 2126 registros de caracter√≠sticas extra√≠das de exames de Cardiotocografias, que foram ent√£o classificados por tr√™s obstetras especialistas em 3 classes:\n",
    "\n",
    "- Normal\n",
    "- Suspeito\n",
    "- Patol√≥gico"
   ],
   "id": "a4dfcf75daf6f0a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1 - Importando os m√≥dulos necess√°rios",
   "id": "cbf2d07f70f3e6ee"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:33.155275Z",
     "start_time": "2025-11-18T22:57:29.174279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Estou rodando copiando o texto original do professor para um novo projeto com o PyCharm.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import random as python_random\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "fccc29d789d3d8a2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Definindo fun√ß√µes adicionais",
   "id": "e3bb04c71bee0523"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:33.164471Z",
     "start_time": "2025-11-18T22:57:33.159288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Esta fun√ß√£o definida no Python ir√° inserir seeds propositais de n√∫mero 42 em todas as fun√ß√µes que utilizam randomiza√ß√£o.\n",
    "# H√° desde fun√ß√µes de ambiente operacional at√© as bibliotecas espec√≠ficas.\n",
    "def reset_seeds() -> None:\n",
    "  \"\"\"\n",
    "  Resets the seeds to ensure reproducibility of results.\n",
    "\n",
    "  This function sets the seed for various random number generation libraries\n",
    "  to ensure that results are reproducible. The affected libraries are:\n",
    "  - Python's built-in `random`\n",
    "  - NumPy\n",
    "  - TensorFlow\n",
    "\n",
    "  The seed used is 42.\n",
    "\n",
    "  Returns:\n",
    "      None\n",
    "  \"\"\"\n",
    "  os.environ['PYTHONHASHSEED']=str(42)\n",
    "  tf.random.set_seed(42)\n",
    "  np.random.seed(42)\n",
    "  random.seed(42)"
   ],
   "id": "276fdc13a1d69e12",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2 - Fazendo a leitura do dataset e atribuindo √†s respectivas vari√°veis",
   "id": "923120280a35955d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:33.413826Z",
     "start_time": "2025-11-18T22:57:33.178517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aqui, de maneira interessante, o professor referencia a vari√°vei data carregando dados que est√£o na Web em seu site.\n",
    "# A biblioteca utilizada para isso √© a Pandas com a fun√ß√£o read_csv. Data ser√° um objeto pandas.core.frame.DataFrame.\n",
    "url = 'raw.githubusercontent.com'\n",
    "username = 'renansantosmendes'\n",
    "repository = 'lectures-cdas-2023'\n",
    "file_name = 'fetal_health_reduced.csv'\n",
    "data = pd.read_csv(f'https://{url}/{username}/{repository}/master/{file_name}')"
   ],
   "id": "1f1b90f3ce139046",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dando uma leve olhada nos dados:",
   "id": "f389c772e73e146a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:33.436830Z",
     "start_time": "2025-11-18T22:57:33.421830Z"
    }
   },
   "cell_type": "code",
   "source": "data.head(30)",
   "id": "7864a77d10379f18",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    severe_decelerations  accelerations  fetal_movement  uterine_contractions  \\\n",
       "0                    0.0            0.0             0.0                   0.0   \n",
       "1                    0.0            6.0             0.0                   6.0   \n",
       "2                    0.0            3.0             0.0                   8.0   \n",
       "3                    0.0            3.0             0.0                   8.0   \n",
       "4                    0.0            7.0             0.0                   8.0   \n",
       "5                    0.0            1.0             0.0                  10.0   \n",
       "6                    0.0            1.0             0.0                  13.0   \n",
       "7                    0.0            0.0             0.0                   0.0   \n",
       "8                    0.0            0.0             0.0                   2.0   \n",
       "9                    0.0            0.0             0.0                   3.0   \n",
       "10                   0.0            0.0             0.0                   1.0   \n",
       "11                   0.0            0.0             0.0                   1.0   \n",
       "12                   0.0            5.0            72.0                   8.0   \n",
       "13                   0.0            9.0           222.0                   6.0   \n",
       "14                   0.0            6.0           408.0                   4.0   \n",
       "15                   0.0            6.0           380.0                   4.0   \n",
       "16                   0.0            6.0           441.0                   5.0   \n",
       "17                   0.0            2.0           383.0                   3.0   \n",
       "18                   0.0            3.0           451.0                   6.0   \n",
       "19                   0.0            5.0           469.0                   5.0   \n",
       "20                   0.0            0.0           340.0                   4.0   \n",
       "21                   0.0            5.0           425.0                   3.0   \n",
       "22                   0.0            0.0           334.0                   3.0   \n",
       "23                   0.0            0.0             0.0                   0.0   \n",
       "24                   0.0            0.0             0.0                   3.0   \n",
       "25                   0.0            0.0             0.0                   0.0   \n",
       "26                   0.0            0.0             0.0                   0.0   \n",
       "27                   0.0            0.0             0.0                   0.0   \n",
       "28                   0.0            0.0           135.0                   1.0   \n",
       "29                   0.0            0.0            99.0                   0.0   \n",
       "\n",
       "    fetal_health  \n",
       "0            2.0  \n",
       "1            1.0  \n",
       "2            1.0  \n",
       "3            1.0  \n",
       "4            1.0  \n",
       "5            3.0  \n",
       "6            3.0  \n",
       "7            3.0  \n",
       "8            3.0  \n",
       "9            3.0  \n",
       "10           2.0  \n",
       "11           2.0  \n",
       "12           1.0  \n",
       "13           1.0  \n",
       "14           1.0  \n",
       "15           1.0  \n",
       "16           1.0  \n",
       "17           2.0  \n",
       "18           1.0  \n",
       "19           1.0  \n",
       "20           3.0  \n",
       "21           1.0  \n",
       "22           3.0  \n",
       "23           3.0  \n",
       "24           3.0  \n",
       "25           3.0  \n",
       "26           3.0  \n",
       "27           3.0  \n",
       "28           2.0  \n",
       "29           1.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severe_decelerations</th>\n",
       "      <th>accelerations</th>\n",
       "      <th>fetal_movement</th>\n",
       "      <th>uterine_contractions</th>\n",
       "      <th>fetal_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3 - Preparando o dado antes de iniciar o treino do modelo",
   "id": "51c98587508d317d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:33.485154Z",
     "start_time": "2025-11-18T22:57:33.476888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Atribuir a X o dataframe data sem a coluna fetal_health. Isto mant√©m apenas as vari√°veis preditoras de features em X.\n",
    "# Em uma √∫nica linha fazemos a atribui√ß√£o a X de uma vers√£o de data com o drop da coluna fetal_health.\n",
    "# Interessante √© que na verdade drop √© um m√©todo de data!\n",
    "X=data.drop([\"fetal_health\"], axis=1)\n",
    "\n",
    "# Aqui fazemos o complemento: atribu√≠mos a y as vari√°veis alvo da coluna fetal_health. Para isto, acessamos especificamente\n",
    "# de data a coluna fetal_health referenciando-a entre colchetes com o nome fetal_health entre aspas.\n",
    "y=data[\"fetal_health\"]\n",
    "\n",
    "# Guardar os nomes das colunas para posterior processamento. Interessante mostrar que se retiram as colunas de X, ou seja,\n",
    "# s√≥ haver√° as colunas dos features, e n√£o da vari√°vel preditora fetal_health.\n",
    "columns_names = list(X.columns)\n",
    "\n",
    "# Criando um objeto para pr√©-processamento dos dados.A classe StandardScaler pertence √† scikit-learn.\n",
    "# Ela padroniza dados, transformando cada feature para que tenha M√©dia = 0 e Desvio Padr√£o = 1. Esta transforma√ß√£o\n",
    "# serve para algoritmos de machine learning, como regress√£o log√≠stica, SVM e Redes Neurais.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Usando o objeto scaler para transformar os valores de X:\n",
    "X_df = scaler.fit_transform(X)\n",
    "\n",
    "# Reconstruindo um Datagrame Pandas com os dados padronizados, juntando com os nomes originais das colunas, que deixamos\n",
    "# guardados em columns_names anteriormente:\n",
    "X_df = pd.DataFrame(X_df, columns=columns_names)\n",
    "\n",
    "# Abaixo, cl√°ssica instru√ß√£o de divis√£o de features e vari√°veis preditoras em conjuntos de treino e de teste utilizando\n",
    "# train_test_split, com 30% para teste. A atribui√ß√£o de 42 ao atributo de entrada random_state permite refazer o teste\n",
    "# tendo o mesmo resultado de distribui√ß√£o aleat√≥ria do conjunto de dados de teste, permitindo rastrear e repetir o passo caso\n",
    "# necess√°rio tendo os mesmos resultados de treinamento e teste. X_df √© o resultado do processamento feito para permitir\n",
    "# o treinamento. Recomenda-se comparar os dois objetos, X e X_df.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Isto aqui √© curioso: subtrai-se 1 das vari√°veis preditoras de treinamento e de teste, provavelmente para ajustar r√≥tulos que\n",
    "# possuem sa√≠das de predi√ß√£o iniciados em 1 para poderem iniciar em zero, mas fica mais claro olhando os resultados depois.\n",
    "y_train = y_train -1\n",
    "y_test = y_test - 1"
   ],
   "id": "a7f2d84a02431ed8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4 - Criando o modelo e adicionando camadas",
   "id": "7c04cfe7a1e09f47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:33.583826Z",
     "start_time": "2025-11-18T22:57:33.535656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cria√ß√£o de camadas de rede neural artificial\n",
    "\n",
    "# A instru√ß√£o abaixo chama a fun√ß√£o criada antes que opera\n",
    "# em todas as partes do c√≥digo e do ambiente que porventura\n",
    "# fa√ßam uso de randomiza√ß√£o para que os passos de separa√ß√µes\n",
    "# ou escolhas aleat√≥rias sejam repetidos. Lembrando a fun√ß√£o:\n",
    "#  os.environ['PYTHONHASHSEED']=str(42): - Define a semente do hash aleat√≥rio usado internamente pelo Python\n",
    "#  tf.random.set_seed(42): Define a semente para o gerador de n√∫meros aleat√≥rios do TensorFlow.\n",
    "#  np.random.seed(42): Define a semente para o gerador de n√∫meros aleat√≥rios do NumPy.\n",
    "#  random.seed(42): Define a semente para o m√≥dulo random da biblioteca padr√£o do Python.\n",
    "reset_seeds()\n",
    "\n",
    "# Aqui define-se uma rede neural sequencial usando a biblioteca Keras.\n",
    "# Para constar, a importa√ß√£o foi feita assim:\n",
    "# from tensorflow import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, InputLayer\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# Criando um modelo Sequential, que √© uma pilha linear de camadas.\n",
    "# Cada camada tem exatamente uma entrada e uma sa√≠da???????\n",
    "model = Sequential()\n",
    "\n",
    "# Definindo a forma de entrada da rede;\n",
    "# input_shape = (X_train.shape[1],) significa que a entrada ser√° um vetor com\n",
    "# o mesmo n√∫mero de colunas (features) que o conjunto de treino X_train.\n",
    "# Esta camada n√£o possui neur√¥nios de ativa√ß√£o. A fun√ß√£o dele √©\n",
    "# estabelecer para a rede neural o formado de entrada dos dados.\n",
    "#model.add(InputLayer(input_shape=(X_train.shape[1], )))\n",
    "model.add(InputLayer(shape=(X_train.shape[1], )))\n",
    "\n",
    "# Adiciona a primeira camada oculta no modo Dense que √© totalmente conectada.\n",
    "# Especifica que esta camada possui 10 neur√¥nios e que usar√° a fun√ß√£o de\n",
    "# ativa√ß√£o ReLU - Rectified Linear Unit, que introduz n√£o linearidade e ajuda\n",
    "# a rede a aprender padr√µes complexos.\n",
    "model.add(Dense(units=10, activation='relu'))\n",
    "\n",
    "# Adiciona mais uma camada oculta igual √† anterior:\n",
    "model.add(Dense(units=10, activation='relu'))\n",
    "\n",
    "# Finalmente, adicionando uma camada final de 3 neur√¥nios que representa os 3\n",
    "# poss√≠veis estados da vari√°vel alvo fetal_health. A fun√ß√£o de ativa√ß√£o softmax\n",
    "# transforma as sa√≠das em probabilidades que somam 1, o que √© ideal para a\n",
    "# classifica√ß√£o multiclasse.\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ],
   "id": "52861d12e899d320",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5 - Compilando o modelo",
   "id": "a2d661bbfbb545cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:33.596376Z",
     "start_time": "2025-11-18T22:57:33.587984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configurando o modelo de rede neural para treinamento utilizando o m√©todo compile():\n",
    "\n",
    "# - loss = 'sparse_categorical_cossentropy': define a fun√ß√£o de perda (loss function) a qual mede o erro entre as previs√µes\n",
    "# e os r√≥tulos reais. a fun√ß√£o de perda escolhida, sparse_categorical_crossentropy √© usada para classifica√ß√£o multiclasse\n",
    "# quando os r√≥tulos s√£o inteiros, tais como 0, 1, 2 e n√£o vetores # one-hot.\n",
    "\n",
    "# - optimizer = 'adam': Define o otimizador, que ajusta os pesos da rede para minimizar a fun√ß√£o de perda. Adam - Adaptive\n",
    "# Moment Estimation √© um dos otimizadores mais populares.\n",
    "\n",
    "# - metrics = ['accuraccy']: define a m√©trica de avalia√ß√£o usada durante o treinamento e valida√ß√£o. accuracy = (n√∫mero de\n",
    "# acertos)/(total de exemplos).\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ],
   "id": "691571796cc0b921",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configurando o MLflow",
   "id": "fa4afad091727b5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:57:36.346722Z",
     "start_time": "2025-11-18T22:57:33.600386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aqui tinha muita coisa pessoal do Professor Renan. Depois adaptei para rodar localmente.\n",
    "# Para isso, antes de rodar o c√≥digo, lembrar de digitar 'mlflow ui' em um prompt de comando para ativar a home page\n",
    "# que vai apresentar os resultados da biblioteca MLflow.\n",
    "import mlflow\n",
    "\n",
    "#os.environ['MLFLOW_TRACKING_USERNAME'] = 'renansantosmendes'\n",
    "#os.environ['MLFLOW_TRACKING_PASSWORD'] = '6d730ef4a90b1caf28fbb01e5748f0874fda6077'\n",
    "#mlflow.set_tracking_uri('https://dagshub.com/renansantosmendes/puc_lectures_mlops.mlflow')\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\") # Vai usar o banco de dados SWLite e o MLflow no meu pr√≥pro computador.\n",
    "\n",
    "mlflow.keras.autolog(log_models=True,\n",
    "                     log_input_examples=True,\n",
    "                     log_model_signatures=True)"
   ],
   "id": "42789544919d5d48",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/18 19:57:36 WARNING mlflow.utils.autologging_utils: MLflow keras autologging is known to be compatible with 3.0.2 <= keras <= 3.9.2, but the installed version is 3.12.0. If you encounter errors during autologging, try upgrading / downgrading keras to a compatible version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6 - Executando o treino do modelo",
   "id": "a1e602bac73442f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:58:01.207666Z",
     "start_time": "2025-11-18T22:57:36.540248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iniciando experimento MLflow com o nome 'experiment_mlops_ead.\n",
    "# Tudo o que acontece dentro do bloco 'with' ser√° registrado automaticamente\n",
    "# pelo MLflow. No caso, ser√£o par√¢metros do modelo, m√©tricas de desempenho\n",
    "# e os artefatos, que no caso √© o modelo treinado. O objeto 'run' representa\n",
    "# a execu√ß√£o atual, permitindo aceso a informa√ß√µes como ID, status e\n",
    "# resultados.\n",
    "\n",
    "with mlflow.start_run(run_name='experiment_mlops_ead') as run:\n",
    "  model.fit(X_train,\n",
    "            y_train,\n",
    "            epochs=50,\n",
    "            validation_split=0.2,\n",
    "            verbose=3)"
   ],
   "id": "4c8794e880682612",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/18 19:57:38 WARNING mlflow.keras.autologging: Unrecognized dataset type <class 'pandas.core.frame.DataFrame'>. Dataset logging skipped.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 2/50\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "Epoch 5/50\n",
      "Epoch 6/50\n",
      "Epoch 7/50\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "Epoch 10/50\n",
      "Epoch 11/50\n",
      "Epoch 12/50\n",
      "Epoch 13/50\n",
      "Epoch 14/50\n",
      "Epoch 15/50\n",
      "Epoch 16/50\n",
      "Epoch 17/50\n",
      "Epoch 18/50\n",
      "Epoch 19/50\n",
      "Epoch 20/50\n",
      "Epoch 21/50\n",
      "Epoch 22/50\n",
      "Epoch 23/50\n",
      "Epoch 24/50\n",
      "Epoch 25/50\n",
      "Epoch 26/50\n",
      "Epoch 27/50\n",
      "Epoch 28/50\n",
      "Epoch 29/50\n",
      "Epoch 30/50\n",
      "Epoch 31/50\n",
      "Epoch 32/50\n",
      "Epoch 33/50\n",
      "Epoch 34/50\n",
      "Epoch 35/50\n",
      "Epoch 36/50\n",
      "Epoch 37/50\n",
      "Epoch 38/50\n",
      "Epoch 39/50\n",
      "Epoch 40/50\n",
      "Epoch 41/50\n",
      "Epoch 42/50\n",
      "Epoch 43/50\n",
      "Epoch 44/50\n",
      "Epoch 45/50\n",
      "Epoch 46/50\n",
      "Epoch 47/50\n",
      "Epoch 48/50\n",
      "Epoch 49/50\n",
      "Epoch 50/50\n",
      "üèÉ View run experiment_mlops_ead at: http://localhost:5000/#/experiments/0/runs/ec03f64445384d35a83b08d69b4a5885\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:58:01.252639Z",
     "start_time": "2025-11-18T22:58:01.249668Z"
    }
   },
   "cell_type": "code",
   "source": "# Funcionou tudo. Agora √© descobrir como utilizar o artefato.",
   "id": "233ee89bbcce68e9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:58:01.260646Z",
     "start_time": "2025-11-18T22:58:01.257646Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "989656f8cdd899f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "282bef5e86c9c010"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
